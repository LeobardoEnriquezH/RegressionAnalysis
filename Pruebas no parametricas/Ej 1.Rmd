---
title: ""
author: ""
date: ""
header-includes:
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}
- \usepackage{graphicx}
- \usepackage{multirow,rotating}
- \usepackage{dcolumn}
- \usepackage{pdflscape}
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=FALSE, include=FALSE}
library(stargazer)
library(Rfit)
library(ggplot2)
```

## Ejercicio 1

En esta sección trabajaremos con datos de colesterol malo (ldl) y cuatro tratamientos (treat: 1,2,3,4) que se probaron para reducir los niveles. Se tienen 39 observaciones aleatorias e independientes en el conjunto de datos ``quail`` de la biblioteca ``Rfit``. A continuación se presenta el BoxPlot, en donde podemos observar que la mediana de ldl para el segundo tratamiento es menor que en los demás casos, y que hay algunos valores que son outliers (los puntos asociados al símbolo de +). No parece que se pudiera asumir que los datos tengan un comportamiento normal para todos los grupos, por ejemplo en el caso del segundo grupo de tratamiento, no hay simetría entre los intercuantiles Q1 y Q3, con una media más cercana al cuantil Q1.  

```{r, echo=FALSE}
datos<-Rfit::quail
```

```{r, echo=FALSE, fig.height=3, fig.width=5}
set.seed(340)
ggplot(datos, aes(x = treat, y = ldl, colour = treat)) + 
  geom_boxplot(outlier.shape = 3) +
  geom_jitter()+theme_bw()
```

```{r normalidad, echo=FALSE}
### Normalidad
library(nortest)
# Lilliefors
norm_g1<-lillie.test(datos$ldl[datos$treat=="1"])
norm_g2<-lillie.test(datos$ldl[datos$treat=="2"])
norm_g3<-lillie.test(datos$ldl[datos$treat=="3"])
norm_g4<-lillie.test(datos$ldl[datos$treat=="4"])
```

En la prueba de normalidad ``Lilliefors (Kolmogorov-Smirnov) normality test`` para cada grupo, tenemos que no se rechaza la hipótesis nula de normalidad, para los grupos 1 y 4, mientras que se rechaza para los grupos 2 y 3.  El p-value para el grupo 1 es de `r norm_g1$p.value`, para el 4 de `r norm_g4$p.value`, para el 2 de `r norm_g2$p.value` y para el 3 de `r norm_g3$p.value`. (Chunk normalidad, linea de código 40)


```{r homocedasticidad, echo=FALSE, include=FALSE, message=FALSE}
#Prueba de homocedasticidad
# H_o: las varianzas de los grupos es la misma vs H_a: al menos un grupo tiene una varianza diferente
bartlett<-bartlett.test(ldl~ treat, data = datos)
#Otra prueba más robusta 
library(car)
levene<-leveneTest(ldl~ treat, data = datos)
levene1<-levene$`Pr(>F)`[1]
fligner<-fligner.test(ldl~ treat, data = datos) #prueba no paramétrica
```

Por otra parte, en las pruebas de homocedasticidad entre grupos, no se rechaza la hipótesis nula de misma varianza, pues el p-value para la prueba de Bartlett es de `r bartlett$p.value`, para la prueba Fligner de `r fligner$p.value` y para la prueba Levene de `r levene1`. (Chunk homocedasticidad, linea de código 53)

```{r, echo=FALSE, include=FALSE, message=FALSE}
### Una alternativa no parámetrica es 
#  la prueba de Kruskal-Wallis
library(PMCMRplus)
### ¿Los grupos son iguales con respecto a la mediana?
#H0: las medianas son iguales vs Ha: al menos dos grupos tienen mediana diferente

#Distribución exacta sobre la estadística que es función de los rangos
kruskalTest1<-kruskalTest(ldl ~ treat, data = datos, dist="KruskalWallis")
```

Si no asumimos ninguna distribución en particular pero sí que es la misma, la prueba Kruskal–Wallis se basa en una transformación de rangos. En este caso no hay problema de varianza heterogénea, por lo que no será necesario esto para comparar grupos. Sin embargo, con esta prueba tenemos que la mediana o la distribución no es la misma en todos los grupos, porque se rechaza la hipótesis nula (p-value de `r kruskalTest1$p.value`), con un nivel de significancia $\alpha=0.1$. El resultado es similar si usamos distribución asintótoca con distribución Chisquare. (Chunk kruskaltest, linea de código 80)


```{r, echo=FALSE, message=FALSE, warning=FALSE}
### Una alternativa no parámetrica es 
#  la prueba de Kruskal-Wallis
library(PMCMRplus)
### ¿Los grupos son iguales con respecto a la mediana?
#H0: las medianas son iguales vs Ha: al menos dos grupos tienen mediana diferente
# Algo equivalente a la prueba de la tabla ANOVA cuando se usa regresión 
# lineal múltiple.
#kruskal.test(ldl ~ treat, data = datos)  #usando distribución asintótica

#Distribución exacta sobre la estadística que es función de los rangos
kruskalTest(ldl ~ treat, data = datos, dist="KruskalWallis")

#Supuesto asintótico (por default)
kruskalTest(ldl ~ treat, data = datos, dist="Chisquare")
```

Además, en las pruebas simultáneas de Dunn, para pares de grupos, se tienen p-values mayores a 0.1 en casi todos los casos, por lo que la dstribución es igual entre los grupos comparados por pares, a excepción de los grupos 1 y 2. (Chunk kwAllPairsDunnTest1, linea de código 100)


```{r kwAllPairsDunnTest1, echo=FALSE, warning=FALSE, message=FALSE}
#Son pruebas simultáneas
ans <- kwAllPairsDunnTest(ldl ~ treat, data = datos)
summary(ans)
```

Comparando un grupo contra todos los demás (ManyOne) usando Dunn test, tenemos que si tomamos el grupo de referencia (Grupo 1), para responder si el grupo 1 es el mejor, hay un p-value menor a 0.1 para la comparación con el grupo 2, lo que rechaza que sean iguales estos grupos. Si cambiamos al grupo de referencia, se rechaza la hipótesis de que éstos dos grupos (1 Y 2) sean iguales en todos los casos. (Chunk kwManyOneDunnTest1, linea de código 108)

```{r kwManyOneDunnTest1, echo=FALSE, warning=FALSE, message=FALSE}
#Por ejemplo. A. Un grupo se toma de referencia y se hacen sólo las comparaciones 
#de ese grupo con los demás
ans1 <- kwManyOneDunnTest(ldl ~ treat, data = datos)
summary(ans1)
levels(datos$treat) #por default se hacen todas las comparaciones contra el grupo de referencia
```

```{r, echo=FALSE}
### si quisieramos comparar el grupo 2 con los demás:
#datos$treat<- relevel(datos$treat, ref = "2")
#ans1 <- kwManyOneDunnTest(ldl ~ treat, data = datos)
#summary(ans1)
```

Haciendo una prueba con dirección, podemos concluir que el grupo 2 es mejor que el grupo 1, pues se rechaza la hipótesis nula, donde la hipótesis alternativa es que el grupo 2 es mejor que el grupo 1, este es el único caso.  (Chunk kwManyOneDunnTestLess, linea de código 125)

```{r kwManyOneDunnTestLess, echo=FALSE, warning=FALSE, message=FALSE}
# B. Se puede especificar sentido para poder obtener más control en la significancia
# Sólo si los investigadores tienen esa hipótesis

ans1 <- kwManyOneDunnTest(ldl ~ treat, data = datos, alternative = "less")
summary(ans1)
# con base en lo último no se puede conluir con alpha=.05 que el grupo 1 es mejor que el grupo 3 y 4, pero sí que el 2.
```

Por otra parte, si hacemos esta misma prueba tomando como referencia al grupo 2, no hay suficiente evidencia para decir que el tratamiento 2 es mejor o reduce más los niveles de colesterol en comparación con el resto de tratamientos.  (Chunk kwManyOneDunnTestLess2, linea de código 136)

```{r kwManyOneDunnTestLess2, echo=FALSE, warning=FALSE, message=FALSE}
### si quisieramos comparar el grupo 2 con los demás:
datos$treat<- relevel(datos$treat, ref = "2")
ans1 <- kwManyOneDunnTest(ldl ~ treat, data = datos, alternative = "less")
summary(ans1)
```


Análogamente, esta prueba se hizo también para los grupos 3 y 4, con lo que tampoco hay suficiente evidencia para afirmar que los tratamientos 3 y 4 pudieran ser mejores que los demás. 

Podemos concluir que el tratamiento 2 es mejor que el 1, sin embargo no es posible afirmar que sea mejor que los tratamientos 3 y 4. En las pruebas de los demás tratamientos, no es posible afirmar que los tratamientos 1,3 y 4 sean mejores que algún otro. 



