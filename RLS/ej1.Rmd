---
title: "Ejercicio 1"
author: "Equipo"
date: "2024-03-26"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 1. Regresión a través del origen.

$$
y_i=\beta x_i+\xi_i \quad i=1 \ldots n
$$
donde $\xi_1, \ldots, \xi_n$ son v.a.i. talque $\xi_i \sim N\left(0, \frac{\sigma^2}{w_i}\right)$
$$
\forall i=1 \ldots n
$$

Suponiendo $\sigma^2$ conocida y $\omega_i=\frac{1}{x_i^2} \quad i=1, \ldots, n$
I)
Como las $\xi_i$ son normales, entonces $y_i \sim N\left(\beta x_i, x_i^2 \sigma^2\right)$ y son independientes, entonces la funcion de verosimilitud nos queda:
$$
\prod_{i=1}^n \frac{1}{\sqrt{2 \pi} x_i \sigma} e^{-\frac{\left(y_i-\beta x_i\right)^2}{2 x_i^2 \sigma^2}}
$$
es decir:
$$
\frac{1}{(2 \pi)^{n / 2} x_i^n \sigma^n} e^{\sum_{i=1}^n \frac{-\left(y_i-\beta x_i\right)^2}{2 x_i^2 \sigma^2}}
$$

Aplicando logaritmo:
$$
\ln (1)-\frac{n}{2} \ln (2 \pi)-n \ln \left(x_i\right)-n \ln (\sigma)+\sum_{i=1}^n \frac{-\left(y_i-\beta x_i\right)^2}{2 x_i^2 \sigma^2}
$$
derivando e igualando a cero obtenemos:
$$
\begin{aligned}
& \frac{d}{d \beta} \ln (f)=-\sum_{i=1}^n \frac{\left(y_i-\beta x_i\right)}{x_i^2 \sigma^2}\left(-x_i\right)=0 \\
& \rightarrow \sum_{i=1}^n \frac{\left(y_i-\beta x_i\right)}{x_i \sigma^2}=0 \rightarrow \sum_{i=1}^n \frac{y_i}{x_i \sigma^2}-\sum_{i=1}^n \frac{\beta}{\sigma^2}=0
\end{aligned}
$$
Asi
$$
\sum_{i=1}^n \frac{y_i}{x_i \sigma^2}=\frac{n \beta}{\sigma^2} \rightarrow \hat{\beta}=\sum_{i=1}^n \frac{y_i}{x_i n}
$$
II)
$$
\begin{aligned}
& \operatorname{Var}(\hat{\beta}) \\
& =\operatorname{Var}\left(\sum_{i=1}^n \frac{y_i}{x_i n}\right)=\frac{1}{n^2} \cdot \operatorname{Var}\left(\sum_{i=1}^n \frac{y_i}{x_i }\right) \\
& =\frac{1}{n^2} \sum_{i=1}^n \operatorname{Var}\left(\frac{y_i}{x_i}\right)=\frac{1}{n^2} \sum_{i=1}^n \frac{1}{x_i{ }^2} \operatorname{Var}\left(y_i\right) \\
& =\frac{1}{n^2} \sum_{i=1}^n \frac{1^2}{x_i^2}\left(x_i^2 \sigma^2\right)=\frac{1}{n^2} \sum_{i=1}^n \sigma^2=\frac{\sigma^2}{n} \\
& \therefore \operatorname{Var}(\hat{\beta})=\frac{\sigma^2}{n}
\end{aligned}
$$
III) Tenemos la funcion de verosimilitud
$$
\frac{1}{\sigma^n(2 \pi)^{n / 2} \prod_{i=1}^n x_i} e^{\sum_{i=1}^n \frac{-\left(y_i-\beta x_i\right)^2}{2 x_i^2 \sigma^2}}
$$
de donde
$$
\begin{aligned}
& e^{\sum \frac{-\left(x_i-\beta x_i\right)^2}{2 x_i^2 \sigma^2}}=e^{\frac{1}{2 \sigma^2} \sum-\frac{\left(y_i-\beta x_i\right)^2}{x_i^2}} \\
& =e^{\frac{1}{2 \sigma^2} \sum-\frac{x_i^2+2\beta x_i y_i-\beta^2 x_i^2}{x_i^2}} \\
& =e^{\frac{1}{2 \sigma^2} \sum \frac{-y_i^2}{x_i^2}+\sum \frac{2 \beta y_i}{x_i}-\sum \beta^2} \\
& =e^{\frac{-\sum \beta^2}{2 \sigma^2}} \cdot e^{\sum \frac{-y_i^2}{x_i^2}+2 \beta \sum \frac{y_i}{x_i}} \\
&
\end{aligned}
$$
Asi
$$
\begin{array}{ll}
a(\gamma)=e^{\frac{-\sum \beta^2}{2 \sigma^2}} & b(x)=\frac{1}{\sigma^n(2 \pi)^{n / 2} \prod x_i} \\
c_1(\gamma)=-1 & d_1(x)=\sum y_i^2 / x_i^2 \\
c_2(\gamma)=2\beta  & d_2(x)=\sum y_i / x_i
\end{array}
$$

Por lo que forma parte de la fam. exponencial.
Observanos: $\sum \frac{y_i}{x_{i}}$ es una estadistica suficiente y completa y $\hat{\beta}=\sum \frac{y_i}{x_{i}n}$ es funcion de $\sum y_i / x_i$
Ademas
$$
\begin{aligned}
\mathbb{E}(\hat{\beta}) & =\mathbb{E}\left(\sum_{i=1}^n \frac{y_i}{x_i n}\right)=\frac{1}{n} \sum_{i=1}^n \mathbb{E}\left(\frac{y_i}{x_i}\right) \\
& =\frac{1}{n} \sum_{i=1}^n \frac{1}{x_i} \mathbb{E}\left(y_i\right)=\frac{1}{n} \sum_{i=1}^n \beta=\beta
\end{aligned}
$$
Por el teorema de Lehman-Scheffe $\hat{\beta}$ es el UMVUE de $\beta$