diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
bc<-car::powerTransform(modelo1)
cat("PowerTransform: \n")
bc
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00~ I(meals+1), data = datos7)
modelo2<-lm(data=datos7, api00^2 ~ I((meals)^(1.2)))
#summary(modelo2)
#stargazer(modelo2)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m2<-augment(modelo2)
normalidad_m2<-ad.test(datos_m2$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
homocedasticidad_m2<-car::ncvTest(modelo2)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo2)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo2)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
curva_ajustada1 <- function(x) {modelo1$coefficients[1] + modelo1$coefficients[2]*x}
curva_ajustada2 <- function(x) {modelo2$coefficients[1] + modelo2$coefficients[2]*x^2}
ggplot(datos7, aes(meals, api00)) +
geom_point() +
geom_function(fun = curva_ajustada1, col="red") +
geom_function(fun = curva_ajustada2, col="blue") + theme_bw()
# Pruebas de hipótesis para beta1
Matriz=matrix(c(0,1), ncol=2, nrow=1)
c=0
#alternative: "two.sided" (default), "greater" or "less"
prueba1=glht(modelo2, linfct=Matriz, rhs=c, alternative="less")
#summary(prueba1)
modelo2<-lm(data=datos7, api00^2 ~ I((meals)^(1)))
#summary(modelo2)
#stargazer(modelo2)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(tidyverse)
library(stargazer)
library(performance)
library(flextable)
library(see)
library(lmtest)
library(qqplotr)
library(ggrepel)
library(patchwork)
library(boot)
library(rempsyc)
library(report)
library(multcomp)
library(car)
library(broom)
datos7<-read_csv("performance.csv", show_col_types = FALSE)
modelo1<-lm(data=datos7, api00~meals)
#summary(modelo1)
#stargazer(modelo1)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo1)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m1<-augment(modelo1)
normalidad_m1<-ad.test(datos_m1$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
library(car)
homocedasticidad_m1<-car::ncvTest(modelo1)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo1)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo1)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo1, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
bc<-car::powerTransform(modelo1)
cat("PowerTransform: \n")
bc
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00~ I(meals+1), data = datos7)
modelo2<-lm(data=datos7, api00^2 ~ I((meals)^(1)))
#summary(modelo2)
#stargazer(modelo2)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m2<-augment(modelo2)
normalidad_m2<-ad.test(datos_m2$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
homocedasticidad_m2<-car::ncvTest(modelo2)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo2)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo2)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
curva_ajustada1 <- function(x) {modelo1$coefficients[1] + modelo1$coefficients[2]*x}
curva_ajustada2 <- function(x) {sqrt(modelo2$coefficients[1] + modelo2$coefficients[2]*x)}
ggplot(datos7, aes(meals, api00)) +
geom_point() +
geom_function(fun = curva_ajustada1, col="red") +
geom_function(fun = curva_ajustada2, col="blue") + theme_bw()
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00^2~ I(meals+1), data = datos7)
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(tidyverse)
library(stargazer)
library(performance)
library(flextable)
library(see)
library(lmtest)
library(qqplotr)
library(ggrepel)
library(patchwork)
library(boot)
library(rempsyc)
library(report)
library(multcomp)
library(car)
library(broom)
datos7<-read_csv("performance.csv", show_col_types = FALSE)
modelo1<-lm(data=datos7, api00~meals)
#summary(modelo1)
#stargazer(modelo1)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo1)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m1<-augment(modelo1)
normalidad_m1<-ad.test(datos_m1$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
library(car)
homocedasticidad_m1<-car::ncvTest(modelo1)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo1)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo1)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo1, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
bc<-car::powerTransform(modelo1)
cat("PowerTransform: \n")
bc
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00^2~ I(meals+1), data = datos7)
modelo2<-lm(data=datos7, I(api00^2) ~ meals)
#summary(modelo2)
#stargazer(modelo2)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m2<-augment(modelo2)
normalidad_m2<-ad.test(datos_m2$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
homocedasticidad_m2<-car::ncvTest(modelo2)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo2)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
modelo2<-lm(data=datos7, I(api00^2) ~ meals)
#summary(modelo2)
stargazer(modelo2)
modelo2<-lm(data=datos7, I(api00^2) ~ meals)
summary(modelo2)
#stargazer(modelo2)
#Linealidad
library(car)
residualPlots(modelo1)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(tidyverse)
library(stargazer)
library(performance)
library(flextable)
library(see)
library(lmtest)
library(qqplotr)
library(ggrepel)
library(patchwork)
library(boot)
library(rempsyc)
library(report)
library(multcomp)
library(car)
library(broom)
datos7<-read_csv("performance.csv", show_col_types = FALSE)
modelo1<-lm(data=datos7, api00~meals)
#summary(modelo1)
#stargazer(modelo1)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo1)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m1<-augment(modelo1)
normalidad_m1<-ad.test(datos_m1$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
library(car)
homocedasticidad_m1<-car::ncvTest(modelo1)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo1)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo1)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo1, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
bc<-car::powerTransform(modelo1)
cat("PowerTransform: \n")
bc
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00^2~ I(meals+1), data = datos7)
modelo2<-lm(data=datos7, I(api00^2) ~ meals)
#summary(modelo2)
#stargazer(modelo2)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m2<-augment(modelo2)
normalidad_m2<-ad.test(datos_m2$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
homocedasticidad_m2<-car::ncvTest(modelo2)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo2)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo2)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
curva_ajustada1 <- function(x) {modelo1$coefficients[1] + modelo1$coefficients[2]*x}
curva_ajustada2 <- function(x) {sqrt(modelo2$coefficients[1] + modelo2$coefficients[2]*x)}
ggplot(datos7, aes(meals, api00)) +
geom_point() +
geom_function(fun = curva_ajustada1, col="red") +
geom_function(fun = curva_ajustada2, col="blue") + theme_bw()
# Pruebas de hipótesis para beta1
Matriz=matrix(c(0,1), ncol=2, nrow=1)
c=0
#alternative: "two.sided" (default), "greater" or "less"
prueba1=glht(modelo2, linfct=Matriz, rhs=c, alternative="less")
summary(prueba1)
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(tidyverse)
library(stargazer)
library(performance)
library(flextable)
library(see)
library(lmtest)
library(qqplotr)
library(ggrepel)
library(patchwork)
library(boot)
library(rempsyc)
library(report)
library(multcomp)
library(car)
library(broom)
datos7<-read_csv("performance.csv", show_col_types = FALSE)
modelo1<-lm(data=datos7, api00~meals)
#summary(modelo1)
#stargazer(modelo1)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo1)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m1<-augment(modelo1)
normalidad_m1<-ad.test(datos_m1$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
library(car)
homocedasticidad_m1<-car::ncvTest(modelo1)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo1)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo1)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo1, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
bc<-car::powerTransform(modelo1)
cat("PowerTransform: \n")
bc
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00^2~ I(meals+1), data = datos7)
modelo2<-lm(data=datos7, I(api00^2) ~ meals)
#summary(modelo2)
#stargazer(modelo2)
#nice_assumptions from package rempsyc
table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
#Normalidad: Ho:Hay normalidad.
library(nortest)
datos_m2<-augment(modelo2)
normalidad_m2<-ad.test(datos_m2$.std.resid)
#No se rechaza Ho, p-value >0.05
#Homocedasticidad: Ho:Varianza constantes.
homocedasticidad_m2<-car::ncvTest(modelo2)
#Se rechaza Ho, p-value <0.05
#Linealidad
library(car)
residualPlots(modelo2)
#Ho: no se necesita transformación para linealidad
#Se rechaza Ho, p-value <0.05
par(mfrow = c(2, 2))
plot(modelo2)
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####
# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]
curva_ajustada1 <- function(x) {modelo1$coefficients[1] + modelo1$coefficients[2]*x}
curva_ajustada2 <- function(x) {sqrt(modelo2$coefficients[1] + modelo2$coefficients[2]*x)}
ggplot(datos7, aes(meals, api00)) +
geom_point() +
geom_function(fun = curva_ajustada1, col="red") +
geom_function(fun = curva_ajustada2, col="blue") + theme_bw()
# Pruebas de hipótesis para beta1
Matriz=matrix(c(0,1), ncol=2, nrow=1)
c=0
#alternative: "two.sided" (default), "greater" or "less"
prueba1=glht(modelo2, linfct=Matriz, rhs=c, alternative="less")
summary(prueba1)
bc<-car::powerTransform(modelo1)
#cat("PowerTransform: \n")
bc
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
#cat("BoxTidwell: \n")
car::boxTidwell(api00^2~ I(meals+1), data = datos7)
