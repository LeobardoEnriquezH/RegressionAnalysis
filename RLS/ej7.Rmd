---
title: ""
author: ""
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE, include=FALSE}
library(kableExtra)
library(tidyverse)
library(stargazer)
library(performance)
library(flextable)
library(see)
library(lmtest)
library(qqplotr)
library(ggrepel)
library(patchwork)
library(boot)
library(rempsyc)
library(report)
library(multcomp)
```


## 7. Regresión lineal simple con datos de "performance".


Consideraremos los datos en la base ``performance.csv`` y las variables: y = academic performance of the school (api00) y x = percentage of students receiving free meals (meals). Estos datos corresponden a una muestra aleatoria de 400 escuelas primarias en California, en donde por escuela se realizaron mediciones que tienen que ver con su desempeño en el año 2000. 

```{r, echo=FALSE}
datos7<-read_csv("performance.csv", show_col_types = FALSE)
```


### i) Regresión lineal simple y verificación de supuestos.

Ajustaremos un modelo de regresión lineal simple del desempeño escolar (api00) en función del procentaje de estudiantes que recibieron desayunos gratuitos en las escuelas (meals). 

```{r, echo=FALSE}
modelo1<-lm(data=datos7, api00~meals)
#summary(modelo1)
#stargazer(modelo1)
```


\begin{table}[!htbp] \centering 
  \caption{MODELO 1} 
  \label{}
\footnotesize
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & api00 \\ 
\hline \\[-1.8ex] 
 meals & $-$4.015$^{***}$ \\ 
  & s.e.(0.097) \\ 
  & p-value: <2e-16 \\ 
  & \\ 
 Constant & 889.783$^{***}$ \\ 
  & (6.622) \\
  & p-value: <2e-16 \\ 
  & \\ 
\hline \\[-1.8ex] 
Observations & 400 \\ 
R$^{2}$ & 0.811 \\ 
Adjusted R$^{2}$ & 0.811 \\ 
Residual Std. Error & 61.877 (df = 398) \\ 
F Statistic & 1,710.691$^{***}$ (df = 1; 398); p-value: < 2.2e-16 \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table}  
 
 

En el siguiente Cuadro se pueden observar las pruebas de Shapiro-Wilk y Breusch-Pagan y Durbin-Watson, en el primer caso de la normalidad el p-value asociado es mayor a 0.05, por lo que no hay evidencia para rechzar las hipótesis nulas de normalidad, sin embargo hay problemas de heterocedasticidad. Como la muestra se generó aleatoriamente, podemos asumir que no tenemos problemas de autocorrelación de los errores.  


```{r, echo=FALSE, warning=FALSE, message=FALSE}
#nice_assumptions from package rempsyc

table_tests<-nice_assumptions(modelo1)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
```



```{r, echo=FALSE}
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)

```


También podemos observar de forma gráfica estos resultados. Observemos la gráfica de **Fitted values** contra **Residuals**, parece haber un problema de linealidad. En la gráfica **Standard Normal distribution Quantiles** contra **Sample Quantile Deviations** tenemos que la normalidad sí se preserva. En la gráfica de **Fitted Values** contra **$\sqrt{|Std. Residuals|}$** parece no haber homogeneidad de la varianza. Y finalmente, en la gráfica de **Leverage(hii)** contra **Std. Residuals** parece no haber valores atípicos influyentes. Entonces podemos concluir que nuestro modelo no cumple con dos supuestos importantes, la linealidad y la homocedasticidad. 


```{r, echo=FALSE, fig.width = 6, fig.height = 4, include=FALSE}
par(mfrow = c(2, 2))
plot(modelo1)
```






```{r, echo=FALSE, warning=FALSE,  message=FALSE, fig.width = 3, fig.height = 2}
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####

# return a list of single plots
diagnostic_plots <- plot(check_model(modelo1, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]


```



### ii) Ajuste de un mejor modelo que cumple los supuestos. 


Debido a que con el primer modelo no se satisfacen los supuestos de linealidad y homocedasticidad procederemos a hacer algunas pruebas para corregir estos problemas. Haremos unas pruebas para ver qué transformación podría ser la adecuada para la variable dependiente e independiente. 



```{r, echo=FALSE}
bc<-car::powerTransform(modelo1)
cat("PowerTransform: \n")
bc
```



```{r, echo=FALSE}
datos7$meals2<-datos7$meals+1 #sumamos 1 porque hay un valor de 0 (no positivo)
cat("BoxTidwell: \n")
car::boxTidwell(api00~ I(meals+1), data = datos7)
```



El resultado de la prueba ``Estimated transformation parameter `` con la función ``powerTransform`` para transformación de tipo BoxCox, para conocer el exponente $\lambda$ de la variable dependiente, muestra que el valor es de `r bc[7]`. Esto sugiere elevar a un exponente de $3/2=1.5$ a la variable dependiente. Por otra parte, la prueba con la función ``BoxTidwell`` para la tranformación de la variable independiente (modificada al sumarle +1) muestra un valor $\lambda$ de $1.2132$ con un p-value asociado de $0.02591$, lo que implica que $\lambda\neq 1$ y hay que transformar a la variable independiente.  

Sin embargo, primero trataremos de hacer cambios a la variable independiente, ya que las transformaciones de la variable dependiente vuelve un poco más complicada la interpretación de los coeficientes estimados y en general el modelo. Primero probaremos con la transformación **cuadrática** a la variable independiente, en caso de que se cumplan los supuestos nos quedaremos con este modelo.        


```{r, echo=FALSE}
modelo2<-lm(data=datos7, api00 ~ I((meals)^(2)))
#summary(modelo2)
#stargazer(modelo2)
```



\begin{table}[!htbp] \centering 
  \caption{MODELO 2} 
  \label{} 
\footnotesize
\begin{tabular}{@{\extracolsep{5pt}}lc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{1}{c}{\textit{Dependent variable:}} \\ 
\cline{2-2} 
\\[-1.8ex] & api00 \\ 
\hline \\[-1.8ex] 
 I((meals)$\hat{\mkern6mu}$(2)) & $-$0.03592$^{***}$ \\ 
  & s.e. (0.0009269) \\ 
  & t value: -38.75 \\
  & Pr(>|t|): <2e-16 \\
  & \\ 
 Constant & 814.761$^{***}$ \\ 
  & s.e. (5.407) \\ 
  & t value: 150.70 \\
  & Pr(>|t|): <2e-16 \\
  & \\ 
\hline \\[-1.8ex] 
Observations & 400 \\ 
R$^{2}$ & 0.790 \\ 
Adjusted R$^{2}$ & 0.790 \\ 
Residual Std. Error & 65.195 (df = 398) \\ 
F Statistic & 1,501.536$^{***}$ (df = 1; 398); p-value: < 2.2e-16 \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{1}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 



En el siguiente Cuadro se pueden observar las pruebas de Shapiro-Wilk y Breusch-Pagan, el p-value asociado es mayor a 0.05 para ambos casos, por lo que no hay evidencia para rechzar las hipótesis nulas de normalidad y homocedasticidad. Como se mencionó anteriormente, la muestra se generó aleatoriamente, por lo que podemos asumir que no tenemos problemas de autocorrelación de los errores. 


```{r, echo=FALSE, warning=FALSE, message=FALSE}
#nice_assumptions from package rempsyc

table_tests<-nice_assumptions(modelo2)
table_tests_fin<-subset(table_tests, select = -c(Model,Diagnostic) )
table_tests_fin<-table_tests_fin[,1:2]
```



```{r, echo=FALSE}
#nice_assumptions()
#table_nice
kable(t(table_tests_fin)) %>%
kable_styling(bootstrap_options = "striped", full_width = F)

```


También podemos observar de forma gráfica estos resultados. 


```{r, echo=FALSE, fig.width = 6, fig.height = 4, include=FALSE}
par(mfrow = c(2, 2))
plot(modelo2)
```






```{r, echo=FALSE, warning=FALSE,  message=FALSE, fig.width = 3, fig.height = 1.9}
par(mfrow = c(2, 2))
#####check_model() function of performance package: Graphs####

# return a list of single plots
diagnostic_plots <- plot(check_model(modelo2, panel = FALSE))
# linearity
diagnostic_plots[[2]]
# normally distributed residuals
diagnostic_plots[[5]] #6
# homoscedasticiy - homogeneity of variance
diagnostic_plots[[3]]
# influential observations - outliers
diagnostic_plots[[4]]


```



### iii)Gráfica de datos originales y las curvas ajustadas de ambos modelos. 


A continuación se muestra la Gráfica de los datos originales y las curvas ajustadas tanto para el primero modelo sin tratamiento de las variables (recta roja) y la curva ajustada del segundo modelo con la variable independiente cuadrática (curva azul). 


```{r, include=FALSE}
curva_ajustada1 <- function(x) {modelo1$coefficients[1] + modelo1$coefficients[2]*x}
curva_ajustada2 <- function(x) {modelo2$coefficients[1] + modelo2$coefficients[2]*x^2}
```




```{r, echo=FALSE, fig.height=2.8, fig.width=6}
ggplot(datos7, aes(meals, api00)) +
  geom_point() +
  geom_function(fun = curva_ajustada1, col="red") +
  geom_function(fun = curva_ajustada2, col="blue") + theme_bw()
```



### iv) Interpretación de la prueba ANOVA y la R^2. 

En el Modelo 2, se tiene un $R^2$ de 0.79, el cual es el coeficiente de determinación que en este caso se interpreta como que el 79% de la variabilidad del rendimiento acedémico en la escuela ``api00`` se explica por el modelo que incluye la variable del porcentaje de estudiantes que reciben desayuno en la esceula ``meal``. Por otra parte, la prueba $F$ asociada a la tabla ANOVA, contrasta en este caso de la regresión lineal simple las hipótesis nula $H_0: \beta_1=0$ contra la alternativa $H_a: \beta_1\neq0$. Como el p-value asociado es menor a $2e-16$ se rechaza $H_0$ con una significancia estadística del 5%, podemos concluir que la inclusión de la variable explicativa ``meal`` ayuda a modelar $E(api00; meal)$. Es decir, el rendimiento acedémico en la escuela ``api00``  se relaciona linealmente con la variable del porcentaje de estudiantes que reciben desayuno en la esceula ``meal``. 


### v) Prueba de hipótesis de investigación. 

Para verificar el argumento de que "A mayor porcentaje de comidas gratis en la escuela es menor el desempeño de la escuela", plantearemos una prueba de hipótesis. Planteamos la hipótesis nula $H_0: \beta_1 \geq0$ contra la alternativa $H_a: \beta_1<0$, donde $\beta_1$ es el parátro estimado asociado a la variable independiente ``meal``. A continuación se muestra la aprueba ``Simultaneous Tests for General Linear Hypotheses``, donde se rechaza esta hipótesis nula, pues el p-valor asociado es menor a 0.05, considerando un nivel del confianza del 95%.





```{r, echo=FALSE}
# Pruebas de hipótesis para beta1
Matriz=matrix(c(0,1), ncol=2, nrow=1)
c=0
#alternative: "two.sided" (default), "greater" or "less"
prueba1=glht(modelo2, linfct=Matriz, rhs=c, alternative="less")
#summary(prueba1)
```


\begin{table}[!htbp] \centering
\footnotesize
\begin{tabular}{|lllll|}
\hline
\multicolumn{5}{|c|}{Simultaneous Tests for General Linear Hypotheses}                                                                                                \\ 
\multicolumn{5}{|c|}{Fit:lm(formula = api00 $\sim$ I((meals)$\wedge$(2)), data = datos7)}                                                                                                    \\
\multicolumn{5}{|l|}{Linear Hypotheses:}                                                                                                                            \\ \hline
\multicolumn{1}{|l|}{}                    & \multicolumn{1}{l|}{Estimate} & \multicolumn{1}{l|}{Std. Error} & \multicolumn{1}{l|}{t value}         & Pr(\textless{}t) \\ \hline
\multicolumn{1}{|l|}{1 >= 0} & \multicolumn{1}{l|}{-0.0359152}  & \multicolumn{1}{l|}{0.0009269}     & \multicolumn{1}{l|}{-38.75}         & <2e-16 ***           \\ \hline
\multicolumn{5}{|l|}{}                             \\ \hline
\multicolumn{1}{|l|}{Signif. codes:}      & \multicolumn{4}{l|}{0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1}                                                       \\ \hline
\multicolumn{5}{|l|}{(Adjusted p values reported -- single-step method)}                                                                                              \\ \hline
\end{tabular}
\end{table}



















