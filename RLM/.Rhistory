knitr::opts_chunk$set(echo = TRUE)
datos6<-read.csv("Ex6.csv")
View(datos6)
dbinom(5, 10, 0.25)
dbinom(x = c(0:10), size = 10, prob = 1/4)
dbinom(x = c(30:40), size = 80, prob = 1/3)
pbinom(5, 10, 0.25)
1-pbinom(5, 10, 0.25)
1-pbinom(6, 10, 0.25)
1-pbinom(4, 10, 0.25)
pbinom(4, 10, 0.25)
pbinom(6, 10, 0.25)
dbinom(x = c(0:10), size = 10, prob = 1/4)
1-dbinom(x = c(0:10), size = 10, prob = 1/4)
pbinom(x = c(0:10), size = 10, prob = 1/4)
pbinom(x = c(0:10), size = 10, prob = 1/4)
1-qbinom(0.0197, size = 10, prob = 1/4)
qbinom(0.0197, size = 10, prob = 1/4
qbinom(0.0197, size = 10, prob = 1/4)
qbinom(1-0.0197, size = 10, prob = 1/4)
qbinom(1-0.0781, 10, prob = 1/4)
pbinom(3, size = 10, prob = 1/4)
pbinom(1, size = 10, prob = 1/4)
pbinom(2, size = 10, prob = 1/4)
pbinom(4, size = 10, prob = 1/4)
pbinom(5, size = 10, prob = 1/4)
pbinom(6, size = 10, prob = 1/4)
pbinom(7, size = 10, prob = 1/4)
1-0.9802723
1-0.9964943
dbinom(6, 10, 1/4)
rbinom(6, 10, 1/4)
dbinom(6, 10, 1/4)
dbinom(4, 10, 1/4)
dbinom(5, 10, 1/4)
pbinom(4, 10, 1/4)
1-pbinom(4, 10, 1/4)
1-pbinom(5, 10, 1/4)
1-pbinom(10-5, size=10, prob=1/4)
qbinom(1-.0781, size=10, prob=1/4)
qbinom(1-0.0197, size=10, prob=1/4)
1-pbinom(10-6, size=10, prob=1/4)
1-pbinom(6, size=10, prob=1/4)
pbinom(10-6, size=10, prob=1/4)
pbinom(6, size=10, prob=1/4)
1-pbinom(6, size=10, prob=1/4)
1-pbinom(10-5, size=10, prob=1/4)
1-pbinom(10-6, size=10, prob=1/4)
1-pbinom(10-5+1, size=10, prob=1/4)
1-pbinom(10-5-1, size=10, prob=1/4)
1-pbinom(10-6-1, size=10, prob=1/4)
View(datos6)
knitr::opts_chunk$set(echo = TRUE)
modelo<-lm(data=datos6, Y~.)
summary(modelo)
datos6<-read.csv("Ex6.csv")
datos6$X1<-as.factor(datos6$X1)
datos6$X2<-as.factor(datos6$X2)
modelo<-lm(data=datos6, Y~.)
summary(modelo)
library(multcomp)
datos <- read.csv("Ex4B.csv")
str(datos)
datos$Sexo=factor(datos$Sexo)
datos$Trat=factor(datos$Trat)
str(datos)
levels(datos$Sexo)
levels(datos$Trat)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
fit <- lm(Puntaje ~ Trat*Sexo, data = datos)
summary(fit)
K=matrix(c(0,0,0,1,0,0,
0,0,0,0,1,0,
0,0,0,0,0,1), ncol=6, nrow=3, byrow=TRUE)
m=c(0,0,0)
summary(glht(fit, linfct=K, rhs=m), test=Ftest())
summary(glht(fit, linfct=K, rhs=m))
fit2 <- lm(Puntaje ~ I(Trat=="Trat1")+I(Trat=="Trat2")+I((Sexo=="Mujer")*(Trat=="Trat2")), data = datos)
summary(fit2)
K2=matrix(c(0,0,-1,0,
0,1,-1,0,
0,-1,-1,0,
0,1,-1,-1), ncol=4, nrow=4, byrow=TRUE)
m2=c(0,0,0,0)
summary(glht(fit2, linfct=K2, rhs=m2, alternative="greater"))
K3=matrix(c(0,-1,0,0,
0,-1,1,0,
0,0,-1,-1,
0,1,-1,-1), ncol=4, nrow=4, byrow=TRUE)
m3=c(0,0,0,0)
summary(glht(fit2, linfct=K3, rhs=m3, alternative="greater"))
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
library(multcomp)
datos <- read.csv("Ex4B.csv")
str(datos)
datos$Sexo=factor(datos$Sexo)
datos$Trat=factor(datos$Trat)
str(datos)
levels(datos$Sexo)
levels(datos$Trat)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
fit <- lm(Puntaje ~ Trat*Sexo, data = datos)
summary(fit)
K=matrix(c(0,0,0,1,0,0,
0,0,0,0,1,0,
0,0,0,0,0,1), ncol=6, nrow=3, byrow=TRUE)
m=c(0,0,0)
summary(glht(fit, linfct=K, rhs=m), test=Ftest())
summary(glht(fit, linfct=K, rhs=m))
fit2 <- lm(Puntaje ~ I(Trat=="Trat1")+I(Trat=="Trat2")+I((Sexo=="Mujer")*(Trat=="Trat2")), data = datos)
summary(fit2)
K2=matrix(c(0,0,-1,0,
0,1,-1,0,
0,-1,-1,0,
0,1,-1,-1), ncol=4, nrow=4, byrow=TRUE)
m2=c(0,0,0,0)
summary(glht(fit2, linfct=K2, rhs=m2, alternative="greater"))
K3=matrix(c(0,-1,0,0,
0,-1,1,0,
0,0,-1,-1,
0,1,-1,-1), ncol=4, nrow=4, byrow=TRUE)
m3=c(0,0,0,0)
summary(glht(fit2, linfct=K3, rhs=m3, alternative="greater"))
Datos<-read.csv("Ex5.csv")
Datos$Trat=factor(Datos$Trat)
plot(Datos$Edad,Datos$Ant,pch=19,col=c("blue","green")[Datos$Trat],xlab = "Edad",ylab = "Anticuerpos")
legend("bottomleft", levels(Datos$Trat),
col = c("blue","green"), pch = 19, inset = 0.01,  pt.cex=1.5,cex = .9, y.intersp = 1.3 , bty="n")
fit <- lm(Ant ~ Edad * Trat, data = Datos)
summary(fit)
library(multcomp)
K=matrix(c(0,0,0,1), ncol=4, nrow=1, byrow=TRUE)
m=c(0)
summary(glht(fit, linfct=K, rhs=m), test=Ftest())
edades.interes<-seq(from=25,to=60,by=1)
length(edades.interes)
KC<-cbind(1,edades.interes,0,0)
KC
KT<-cbind(1,edades.interes,1,edades.interes)
KT
K=rbind(KC,KT)
fitE<-glht(fit,linfct = K)
fitci<-confint(fitE,level = 0.90)
plot(Datos$Edad,Datos$Ant,pch=19,col=c("blue","green")[Datos$Trat],xlab = "Edad",ylab = "Anticuerpos")
legend("bottomleft", levels(Datos$Trat),
col = c("blue","green"), pch = 19, inset = 0.01,  pt.cex=1.5,cex = .9, y.intersp = 1.3 , bty="n")
lines(edades.interes,coef(fitE)[1:36],col="red")
lines(edades.interes,fitci$confint[1:36,"upr"],col="red")
lines(edades.interes,fitci$confint[1:36,"lwr"],col="red")
lines(edades.interes,coef(fitE)[37:72],col="black")
lines(edades.interes,fitci$confint[37:72,"upr"],col="black")
lines(edades.interes,fitci$confint[37:72,"lwr"],col="black")
knitr::opts_chunk$set(echo = T, fig.width = 6, fig.height = 3.5)
#rm(list = ls())
pacman::p_load(tidyverse,ISLR,forcats,broom,factoextra,gridExtra,psych,car,nortest,
kableExtra,data.table,NbClust,cowplot,clValid,factorextra,leaps,
stargazer,knitr,viridis,dplyr,readr,scales,quantmod,texreg,tinytex,
tidyr, imager,lubridate,tseries, astsa, growthrates, tis, dynlm,
readxl, foreign, hrbthemes, gtsummary, corrplot, lm.beta, ggfortify,
AER, lmtest, sandwich,GGally, ggplot2, multcomp, purrr, VGAM, lessR,
flextable, performance, see,qqplotr, ggrepel, patchwork,boot,rempsyc,
report, ggResidpanel,DHARMa, SuppDists, glmnet)
ventas<-c(12,10,15,17,11,11,17,16,14,15,27,34,22,26,28,23,20,18,17)
cereal<-c(1,1,1,1,1,2,2,2,2,2,3,3,3,3,3,4,4,4,4)
data<-cbind(ventas,cereal)
data<-as.data.frame(data)
data$cereal<-as.factor(data$cereal)
data %>%
ggplot( aes(x=cereal, y=ventas, fill=cereal)) +
geom_boxplot() +
scale_fill_viridis(discrete = TRUE, alpha=0.6, option="A") + theme_bw()+
theme(
legend.position="none",
plot.title = element_text(size=11)
) +
ggtitle("Ventas por tipo de cereal") +
xlab("")
modelo<-lm(data=data, ventas~cereal)
summary(modelo)
b0<-modelo$coefficients[1]
b1<-modelo$coefficients[2]
b2<-modelo$coefficients[3]
b3<-modelo$coefficients[4]
b0_b1<-modelo$coefficients[1]+modelo$coefficients[2]
b0_b2<-modelo$coefficients[1]+modelo$coefficients[3]
b0_b3<-modelo$coefficients[1]+modelo$coefficients[4]
K=matrix(c(0,1,0,0,
0,0,1,0,
0,0,0,1,
0,1,-1,0,
0,1,0,-1,
0,0,1,-1), ncol=4, nrow=6, byrow=TRUE)
m=c(0,0,0,0,0,0)
summary(glht(modelo, linfct=K, rhs=m))
K=matrix(c(0,0,1,0,
0,-1,1,0,
0,0,1,-1), ncol=4, nrow=3, byrow=TRUE)
m=c(0,0,0)
summary(glht(modelo, linfct=K, rhs=m, alternative="great"))
library(multcomp)
datos <- read.csv("Ex4B.csv")
str(datos)
datos$Sexo=factor(datos$Sexo)
datos$Trat=factor(datos$Trat)
str(datos)
levels(datos$Sexo)
levels(datos$Trat)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
fit <- lm(Puntaje ~ Trat*Sexo, data = datos)
summary(fit)
K=matrix(c(0,0,0,1,0,0,
0,0,0,0,1,0,
0,0,0,0,0,1), ncol=6, nrow=3, byrow=TRUE)
m=c(0,0,0)
summary(glht(fit, linfct=K, rhs=m), test=Ftest())
summary(glht(fit, linfct=K, rhs=m))
fit2 <- lm(Puntaje ~ I(Trat=="Trat1")+I(Trat=="Trat2")+I((Sexo=="Mujer")*(Trat=="Trat2")), data = datos)
summary(fit2)
K2=matrix(c(0,0,-1,0,
0,1,-1,0,
0,-1,-1,0,
0,1,-1,-1), ncol=4, nrow=4, byrow=TRUE)
m2=c(0,0,0,0)
summary(glht(fit2, linfct=K2, rhs=m2, alternative="greater"))
K3=matrix(c(0,-1,0,0,
0,-1,1,0,
0,0,-1,-1,
0,1,-1,-1), ncol=4, nrow=4, byrow=TRUE)
m3=c(0,0,0,0)
summary(glht(fit2, linfct=K3, rhs=m3, alternative="greater"))
Datos<-read.csv("Ex5.csv")
Datos$Trat=factor(Datos$Trat)
plot(Datos$Edad,Datos$Ant,pch=19,col=c("blue","green")[Datos$Trat],xlab = "Edad",ylab = "Anticuerpos")
legend("bottomleft", levels(Datos$Trat),
col = c("blue","green"), pch = 19, inset = 0.01,  pt.cex=1.5,cex = .9, y.intersp = 1.3 , bty="n")
fit <- lm(Ant ~ Edad * Trat, data = Datos)
summary(fit)
library(multcomp)
K=matrix(c(0,0,0,1), ncol=4, nrow=1, byrow=TRUE)
m=c(0)
summary(glht(fit, linfct=K, rhs=m), test=Ftest())
edades.interes<-seq(from=25,to=60,by=1)
length(edades.interes)
KC<-cbind(1,edades.interes,0,0)
KC
KT<-cbind(1,edades.interes,1,edades.interes)
KT
K=rbind(KC,KT)
fitE<-glht(fit,linfct = K)
fitci<-confint(fitE,level = 0.90)
plot(Datos$Edad,Datos$Ant,pch=19,col=c("blue","green")[Datos$Trat],xlab = "Edad",ylab = "Anticuerpos")
legend("bottomleft", levels(Datos$Trat),
col = c("blue","green"), pch = 19, inset = 0.01,  pt.cex=1.5,cex = .9, y.intersp = 1.3 , bty="n")
lines(edades.interes,coef(fitE)[1:36],col="red")
lines(edades.interes,fitci$confint[1:36,"upr"],col="red")
lines(edades.interes,fitci$confint[1:36,"lwr"],col="red")
lines(edades.interes,coef(fitE)[37:72],col="black")
lines(edades.interes,fitci$confint[37:72,"upr"],col="black")
lines(edades.interes,fitci$confint[37:72,"lwr"],col="black")
datos6<-read.csv("Ex6.csv")
datos6$X1<-as.factor(datos6$X1)
datos6$X2<-as.factor(datos6$X2)
modelo1<-lm(data=datos6, Y~.)
summary(modelo1)
#stargazer(modelo1, no.space=TRUE)
par(mfrow=c(1,2))
#par(mar=c(4, 5, 3, 1))
plot(modelo1, 1)   #linealidad
plot(modelo1, 3)   #homocedasticidad
plot(modelo1, 2)   #normalidad
plot(modelo1, 5)   #Outliers
#Varianza constante
#Se basa en los errores estandarizados o estudentizados
#Mismas pruebas usadas en regresiÃ³n lineal simple:
library(lmtest)
sbpt1<-lmtest::bptest(modelo1) #NO se rechaza H0 de homocedasticidad, NO hay problemas
sbpt1p<-sbpt1$p.value #p-value de la prueba Breusch Pagan estudentizado
#Normalidad
#Se basa en los residuales estandarizados o estudentizados
#Mismas pruebas que se usaron en regresi?n lineal simple:
library(broom)
Datosmodelo1=augment(modelo1)
swt1<-shapiro.test(Datosmodelo1$.std.resid) #Se rechaza H0 de normalidad, hay problemas
swt1p<-swt1$p.value
library(nortest)
kst1<-nortest::lillie.test(Datosmodelo1$.std.resid)#Se rechaza H0 de normalidad, hay problemas
kst1p<-kst1$p.value
library(tseries)
jbt1<-tseries::jarque.bera.test(Datosmodelo1$.std.resid)#Se rechaza H0 de normalidad, hay problemas
jbt1p<-jbt1$p.value
#par(mfrow=c(1,1))
library(car)
residualPlots_modelo1<-residualPlots(modelo1) #se observan problemas con X4 y X6
residualPlots_modelo1[,2]
par(mfrow=c(1,2))
residualPlots(modelo1, terms= ~ X1,fitted=FALSE)
residualPlots(modelo1, terms= ~ X2,fitted=FALSE)
residualPlots(modelo1, terms= ~ X3,fitted=FALSE)
residualPlots(modelo1, terms= ~ X4,fitted=FALSE)
residualPlots(modelo1, terms= ~ X5,fitted=FALSE)
residualPlots(modelo1, terms= ~ X6,fitted=FALSE)
library(car)
#GrÃ¡ficas condicionales.
#Dado el resto de variables, la relaciÃ³n es lineal?
#se compara con un polinomio (rosa) para ver si podrÃ­a realizarse alguna modificaciÃ³n
crPlots(modelo1, order=2) #mucho problema con X4 y X6, jugar con order
#crPlots(modelo, terms= ~ X4, order=2)
summary(powerTransform(modelo1))
boxTidwell(I((Y)^2)~I(X6+5.5), ~X1+X2+X3+X4+X5 , data=datos6)
boxTidwell(I((Y)^2)~ X4, ~X1+X2+X3+X5+X6 , data=datos6)
#se considera un modelo con un polinomio de grado 2
#para la variable X6
modelo2=lm(I((Y)^2)~X1+X2+X3+I(X4^(1/2))+X5+X6, data=datos6)
summary(modelo2)
#par(mfrow=c(1,1))
library(car)
residualPlots_modelo2<-residualPlots(modelo2) #se observan problemas con X4 y X6
residualPlots_modelo2[,2]
#Varianza constante
#Se basa en los errores estandarizados o estudentizados
#Mismas pruebas usadas en regresiÃ³n lineal simple:
library(lmtest)
sbpt2<-lmtest::bptest(modelo2) #NO se rechaza H0 de homocedasticidad, NO hay problemas
sbpt2p<-sbpt2$p.value #p-value de la prueba Breusch Pagan estudentizado
#Normalidad
#Se basa en los residuales estandarizados o estudentizados
#Mismas pruebas que se usaron en regresi?n lineal simple:
library(broom)
Datosmodelo2=augment(modelo2)
swt2<-shapiro.test(Datosmodelo2$.std.resid) #Se rechaza H0 de normalidad, hay problemas
swt2p<-swt2$p.value
library(nortest)
kst2<-nortest::lillie.test(Datosmodelo2$.std.resid)#Se rechaza H0 de normalidad, hay problemas
kst2p<-kst2$p.value
library(tseries)
jbt2<-tseries::jarque.bera.test(Datosmodelo2$.std.resid)#Se rechaza H0 de normalidad, hay problemas
jbt2p<-jbt2$p.value
#Mejor subconjunto
library(leaps)
subconjuntos<-regsubsets(I((Y)^2)~X1+X2+X3+I(X4^(1/2))+X5+X6, data=datos6, nbest=2, nvmax=10)
#summary(subconjuntos)
###algunas graficas interesantes para analizar los resultados con cada criterio
###bic, adjr2, Cp
plot(subconjuntos ,scale="bic")
####modelo descrito en renglÃ³n 15
coef(subconjuntos, 15)
modelo3=lm(I((Y)^2)~X1+X2+I(X4^(1/2))+X6, data=datos6) #modelo descrito en renglon 15
summary(modelo3)
("BIC")
BIC_modelo3<-BIC(modelo3)
BIC_modelo3
#Metodos por pasos backward
##k es la penalizacion, 2 para AIC, log(n) para BIC
fitCompleto=lm(I((Y)^2)~X1+X2+X3+I(X4^(1/2))+X5+X6, data=datos6)
#step(fitCompleto,direction="backward", k = 2)   #Usando AIC y empezando con fitCompleto
#agregar trace=0 para eliminar la impresion de los pasos
step(fitCompleto,direction="backward", k = log(400), trace=0)
#Metodos por pasos forward
##k es la penalizacion, 2 para AIC, log(n) para BIC
fitNulo=lm(I((Y)^2)~1, data=datos6)
step(fitNulo,direction="forward", k = log(400), scope=  ~ X1+X2+X3+I(X4^(1/2))+X5+X6, trace=0)  #Usando AIC y empezando con fitNulo
#Usando lasso #seleccion via penalizacion en la logverosimilitud
# paquete smurf #otra opcion mas popular es glmnet
library(smurf)
formu <- I((Y)^2) ~ p(X1, pen = "gflasso") + p(X2, pen = "gflasso")+
p(X3, pen = "lasso") + p(I(X4^(1/2)), pen = "lasso") + p(X5, pen = "lasso") + p(X6, pen = "lasso")
#Usando la muestra completa
glm_lambdabic <- glmsmurf(formula = formu, family = gaussian(), data = datos6,
pen.weights = "glm.stand", lambda = "is.bic")
plot_lambda(glm_lambdabic)
("lambda")
glm_lambdabic$lambda
BIC_glm<-BIC(glm_lambdabic)
plot(glm_lambdabic, cex=3)
summary(glm_lambdabic)
glm_lambdabica <- glmsmurf(formula = formu, family = gaussian(), data = datos6,
pen.weights = "glm.stand", lambda = glm_lambdabic$lambda, x.return=TRUE)
modsellasso=lm(V1~-1+.,as.data.frame(cbind(glm_lambdabica$y, as.matrix(glm_lambdabica$X.reest))) )
summary(modsellasso)
("BIC")
BIC_lasso<-BIC(modsellasso)
BIC_lasso
names(modsellasso$coefficients)<-c("(Intercept)", "X1A2", "X1A3.4", "X2B2.3", "X2B4", "I(X4^(1/2))", "X6")
modsellasso$coefficients
par(mfrow=c(1,2))
plot(subconjuntos ,scale="bic")
plot(glm_lambdabic, cex=3)
#stargazer(modelo1, modelo2, modelo3, modsellasso, no.space=TRUE)
library(multcomp)
datos <- read.csv("Ex4B.csv")
str(datos)
datos$Sexo=factor(datos$Sexo)
datos$Trat=factor(datos$Trat)
str(datos)
levels(datos$Sexo)
levels(datos$Trat)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
par(cex.axis=1.5)
par(cex.axis=1.5)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
par(cex.axis=1.5)
par(cex.axis=0.5)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
par(cex.axis=1.5)
par(cex.axis=0.8)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
par(cex.axis=1.5)
par(cex.axis=0.8)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
par(cex.axis=1.5)
par(cex.axis=0.8)
boxplot(Puntaje ~ Trat+Sexo, data = datos, col = "white", outline=FALSE)
par(cex.axis=1.5)
library(multcomp)
datos <- read.csv("Ex4B.csv")
str(datos)
datos$Sexo=factor(datos$Sexo)
datos$Trat=factor(datos$Trat)
str(datos)
levels(datos$Sexo)
levels(datos$Trat)
